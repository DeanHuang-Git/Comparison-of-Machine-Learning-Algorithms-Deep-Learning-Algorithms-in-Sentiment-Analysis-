{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from sklearn import utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('w2v_yelp.csv')\n",
    "df = df[['Review_Labels', 'cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 99999 .\n"
     ]
    }
   ],
   "source": [
    "print(\"total: %d .\" % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Labels</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20019</th>\n",
       "      <td>2</td>\n",
       "      <td>thi place awesom mean blind remot control open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29954</th>\n",
       "      <td>2</td>\n",
       "      <td>bone wing mild deep dish pizza sooooo good ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98798</th>\n",
       "      <td>2</td>\n",
       "      <td>ah sushi bloor long known mani year eat shiita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43002</th>\n",
       "      <td>2</td>\n",
       "      <td>daughter love maria elena alway pleas alway fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86526</th>\n",
       "      <td>2</td>\n",
       "      <td>love thi place work hard good unlik fight styl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75491</th>\n",
       "      <td>2</td>\n",
       "      <td>wa fortun enough get invit grand open event ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>2</td>\n",
       "      <td>like dark chocol thi place went whim friend bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>2</td>\n",
       "      <td>everyon friendli great servic warm welcom plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96498</th>\n",
       "      <td>0</td>\n",
       "      <td>veri disappoint valentin day dinner thi ha fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>0</td>\n",
       "      <td>send steak back time unaccept medium rare diff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review_Labels                                            cleaned\n",
       "20019              2  thi place awesom mean blind remot control open...\n",
       "29954              2  bone wing mild deep dish pizza sooooo good ser...\n",
       "98798              2  ah sushi bloor long known mani year eat shiita...\n",
       "43002              2  daughter love maria elena alway pleas alway fe...\n",
       "86526              2  love thi place work hard good unlik fight styl...\n",
       "75491              2  wa fortun enough get invit grand open event ne...\n",
       "10078              2  like dark chocol thi place went whim friend bi...\n",
       "19558              2  everyon friendli great servic warm welcom plac...\n",
       "96498              0  veri disappoint valentin day dinner thi ha fav...\n",
       "3814               0  send steak back time unaccept medium rare diff..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['someon', 'ha', 'work', 'mani', 'museum', 'wa', 'eager', 'visit', 'thi', 'galleri', 'recent', 'trip', 'la', 'vega', 'saw', 'would', 'show', 'infam', 'egg', 'hous', 'faberg', 'virginia', 'museum', 'fine', 'art', 'vmfa', 'knew', 'go', 'tuck', 'away', 'near', 'gelateria', 'garden', 'galleri', 'pretti', 'much', 'hidden', 'view', 'real', 'estat', 'agent', 'would', 'call', 'cozi', 'charm', 'basic', 'ani', 'euphem', 'small', 'said', 'still', 'see', 'wonder', 'art', 'galleri', 'ani', 'size', 'whi', 'two', 'ask', 'let', 'tell', 'price', 'thi', 'rel', 'inexpens', 'la', 'vega', 'attract', 'complet', 'top', 'space', 'amount', 'art', 'fit', 'bit', 'much', 'kid', 'friendli', 'serious', 'bring', 'secur', 'train', 'properli', 'show', 'curat', 'design', 'team', 'collabor', 'exhibit', 'definit', 'flow', 'mean', 'visitor', 'view', 'art', 'certain', 'sequenc', 'whether', 'histor', 'period', 'cultur', 'signific', 'thi', 'audio', 'guid', 'usual', 'develop', 'arriv', 'galleri', 'could', 'tell', 'start', 'secur', 'wa', 'certainli', 'help', 'wa', 'told', 'look', 'around', 'whatev', 'fine', 'institut', 'find', 'lack', 'knowledg', 'respect', 'art', 'appal']\n"
     ]
    }
   ],
   "source": [
    "text = df.iloc[0][1]\n",
    "token = nltk.word_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cut_review'] = df['cleaned'].apply(lambda x: [w for w in list(nltk.word_tokenize(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42,stratify = df.Review_Labels.values)\n",
    " \n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=r['cut_review'], tags=[r['Review_Labels']]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=r['cut_review'], tags=[r['Review_Labels']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['someon', 'ha', 'work', 'mani', 'museum', 'wa', 'eager', 'visit', 'thi', 'galleri', 'recent', 'trip', 'la', 'vega', 'saw', 'would', 'show', 'infam', 'egg', 'hous', 'faberg', 'virginia', 'museum', 'fine', 'art', 'vmfa', 'knew', 'go', 'tuck', 'away', 'near', 'gelateria', 'garden', 'galleri', 'pretti', 'much', 'hidden', 'view', 'real', 'estat', 'agent', 'would', 'call', 'cozi', 'charm', 'basic', 'ani', 'euphem', 'small', 'said', 'still', 'see', 'wonder', 'art', 'galleri', 'ani', 'size', 'whi', 'two', 'ask', 'let', 'tell', 'price', 'thi', 'rel', 'inexpens', 'la', 'vega', 'attract', 'complet', 'top', 'space', 'amount', 'art', 'fit', 'bit', 'much', 'kid', 'friendli', 'serious', 'bring', 'secur', 'train', 'properli', 'show', 'curat', 'design', 'team', 'collabor', 'exhibit', 'definit', 'flow', 'mean', 'visitor', 'view', 'art', 'certain', 'sequenc', 'whether', 'histor', 'period', 'cultur', 'signific', 'thi', 'audio', 'guid', 'usual', 'develop', 'arriv', 'galleri', 'could', 'tell', 'start', 'secur', 'wa', 'certainli', 'help', 'wa', 'told', 'look', 'around', 'whatev', 'fine', 'institut', 'find', 'lack', 'knowledg', 'respect', 'art', 'appal'], tags=[0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69999/69999 [00:00<00:00, 2643589.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    " \n",
    "model_dbow = Doc2Vec(dm=0,  negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69999/69999 [00:00<00:00, 2603064.89it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3597254.07it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3485700.72it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3558321.24it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3656434.76it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3667213.16it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3624834.38it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3100318.75it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3670651.82it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3733431.91it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3612479.98it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3612257.75it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3655660.80it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3601136.84it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3238905.71it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3583117.75it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3716277.68it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3683777.74it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3589864.71it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3713269.58it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3651477.96it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3619918.20it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3652068.44it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3542093.98it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3157127.65it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3577834.34it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3425630.48it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3329331.36it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3618267.57it/s]\n",
      "100%|██████████| 69999/69999 [00:00<00:00, 3609681.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 9.43 s, total: 2min 53s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n",
    " \n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=11)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  693    84  5810]\n",
      " [  323    43  2984]\n",
      " [ 1640   217 18206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.11      0.15      6587\n",
      "           1       0.12      0.01      0.02      3350\n",
      "           2       0.67      0.91      0.77     20063\n",
      "\n",
      "    accuracy                           0.63     30000\n",
      "   macro avg       0.35      0.34      0.32     30000\n",
      "weighted avg       0.52      0.63      0.55     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
